{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fahriyegrl/NJIT_Modern_CNN_Assignment/blob/main/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tajfsk_7JY3E"
      },
      "source": [
        "**Note to grader:** Each question consists of parts, e.g. Q1(i), Q1(ii), etc. Each part must be first graded  on a 0-4 scale, following the standard NJIT convention (A:4, B+: 3.5, B:3, C+: 2.5, C: 2, D:1, F:0). However, any given item may be worth 4 or 8 points; if an item is worth 8 points, you need to accordingly scale the 0-4 grade.\n",
        "\n",
        "\n",
        "The total score must be re-scaled to 100. That should apply to all future assignments so that Canvas assigns the same weight on all assignments.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SArgW_Vq-uTh"
      },
      "source": [
        "# <font color = 'blue'>  **Assignment 2**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparation Steps\n"
      ],
      "metadata": {
        "id": "fKHAiVXNz-2i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "We will work with this [mystery dataset](https://drive.google.com/open?id=1WLnWBThCYZ25pReI5DCwk2bgDaCrJxI_&authuser=ikoutis%40njit.edu&usp=drive_fs) that you can download and place to your google drive. You can then put it somewhere on your google drive and bring it into your Colab by following the steps in the following cell.\n",
        "\n"
      ],
      "metadata": {
        "id": "5xtT_YAhmmXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "import scipy.io\n",
        "\n",
        "#mat = scipy.io.loadmat('/content/gdrive/Shareddrives/graph-modification/data/mysteryDataset.mat')\n",
        "\n",
        "#mat = scipy.io.loadmat('/mysteryDataset.mat')"
      ],
      "metadata": {
        "id": "5AMaVk7jmn_D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8cdce30-e505-49e3-d4cb-071123233dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The file contains\n",
        "\n",
        "* Two matrices $X$ and $X_1$ of numerical features. These datasets have the same dimensions (169343x80) but they are different.\n",
        "* An array $y$ of labels, ranging from 0-39.\n",
        "* The indices $otrain$ of a training set. These indices tell you what rows of the arrays $X,X_1,y$ correspond to the training points. You can use these to make two different training sets $(X[train], y[train])$ and $(X_1[train], y[train])$\n",
        "* Similarly, it contains the indexes for a validation and a test set, $ovalid$ and $otest$ respectively.\n",
        "\n",
        "The following cell shows how to access these arrays and assign them to local numpy objects."
      ],
      "metadata": {
        "id": "AsLbaghZrO-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mat = scipy.io.loadmat('mysteryDataset.mat')\n",
        "\n",
        "file_path = \"/content/gdrive/My Drive/mysteryDataset .mat\"\n",
        "mat = scipy.io.loadmat(file_path)"
      ],
      "metadata": {
        "id": "HQ0Oyva2F3fF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mat.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFzCOuH97O0G",
        "outputId": "6da5de83-1305-41cc-df62-a7e70bee05c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['__header__', '__version__', '__globals__', 'X', 'X1', 'otest', 'otrain', 'ovalid', 'y'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = mat['X']\n",
        "print(type(data))\n",
        "print(data.shape)\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slka77ZW7MEV",
        "outputId": "19c34172-8a6c-4614-deae-3ad5085cd3cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(169343, 80)\n",
            "[[-1.17172086e-05 -7.25280867e-06  5.12661752e-06 ...  8.41897191e-05\n",
            "   1.42267498e-05 -1.79510200e-05]\n",
            " [-1.11324893e-05 -4.08813759e-06  2.02800221e-06 ... -8.28714325e-05\n",
            "  -1.61708374e-05  1.97942889e-05]\n",
            " [-1.15048231e-05 -5.82459697e-06  4.93125101e-06 ...  2.49504038e-05\n",
            "   4.74029309e-06 -8.01156192e-06]\n",
            " ...\n",
            " [-1.14174907e-05 -6.78472981e-06  5.12786880e-06 ...  8.45869596e-05\n",
            "   1.28441318e-05 -5.47867305e-06]\n",
            " [-1.17641029e-05 -7.40347110e-06  5.22326732e-06 ...  9.09224602e-05\n",
            "   1.51560773e-05 -1.93930956e-05]\n",
            " [-1.16459906e-05 -4.51781688e-06  4.84513313e-06 ... -6.45753345e-06\n",
            "  -3.49332467e-06 -1.98055043e-05]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is an example\n",
        "#ft = mat.get('X')\n"
      ],
      "metadata": {
        "id": "d0jvswNpwsOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color = 'blue'> Question 1. Import the dataset and conver to torch tensors </font>\n",
        "\n",
        "Your task for this question is to adapt the above preparation steps, import all mentioned variables into numpy arrays, and then transform them to PyTorch tensors.\n"
      ],
      "metadata": {
        "id": "ALSnNeSw0JoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## your answer goes here\n",
        "\n",
        "## Getting the data\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "X = mat['X']\n",
        "X1 = mat['X1']\n",
        "y = mat['y'].flatten()\n",
        "print(X.shape)\n",
        "print(X1.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "C20aEPMG0z2W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50a81d23-d813-4b7b-cef9-dd066255aa66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(169343, 80)\n",
            "(169343, 80)\n",
            "(169343,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.max(), y.min(),y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEigEKzLb0aL",
        "outputId": "59c6b4ab-8107-4fa2-b315-86bfc6206212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39, 0, array([ 4,  5, 28, ..., 10,  4,  1]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "otrain = mat['otrain'].flatten() # Getting training indices\n",
        "ovalid = mat['ovalid'].flatten() # Validation indices\n",
        "otest = mat['otest'].flatten()    # Test indices"
      ],
      "metadata": {
        "id": "bhkRQdaE8qpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(otrain.shape)\n",
        "print(ovalid.shape)\n",
        "print(otest.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FECrBxn481z5",
        "outputId": "742aad8b-ce80-49ed-fd65-afa159c1533f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(90941,)\n",
            "(29799,)\n",
            "(48603,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Converting to PyTorch tensors\n",
        "\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "X1_tensor = torch.tensor(X1, dtype=torch.float32)\n",
        "\n",
        "\n",
        "y_tensor = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "\n",
        "otrain_tensor = torch.tensor(otrain, dtype=torch.long)\n",
        "ovalid_tensor = torch.tensor(ovalid, dtype=torch.long)\n",
        "otest_tensor = torch.tensor(otest, dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "IZjEA-FX8_0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Getting the train, validation, test datasets\n",
        "\n",
        "# Create training sets\n",
        "X_train = X_tensor[otrain_tensor]\n",
        "X1_train = X1_tensor[otrain_tensor]\n",
        "y_train = y_tensor[otrain_tensor]\n",
        "\n",
        "# Create validation sets\n",
        "X_valid = X_tensor[ovalid_tensor]\n",
        "X1_valid = X1_tensor[ovalid_tensor]\n",
        "y_valid = y_tensor[ovalid_tensor]\n",
        "\n",
        "# Create test sets\n",
        "X_test = X_tensor[otest_tensor]\n",
        "X1_test = X1_tensor[otest_tensor]\n",
        "y_test = y_tensor[otest_tensor]\n"
      ],
      "metadata": {
        "id": "mxhz34869FFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X1_train shape:\", X1_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"***************************************\")\n",
        "print(\"X_valid shape:\", X_valid.shape)\n",
        "print(\"X1_valid shape:\", X1_valid.shape)\n",
        "print(\"y_valid shape:\", y_valid.shape)\n",
        "print(\"***************************************\")\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"X1_test shape:\", X1_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFvreG3Y9r8S",
        "outputId": "8332d0da-3a64-457d-ddc5-4ed5e2914237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: torch.Size([90941, 80])\n",
            "X1_train shape: torch.Size([90941, 80])\n",
            "y_train shape: torch.Size([90941])\n",
            "***************************************\n",
            "X_valid shape: torch.Size([29799, 80])\n",
            "X1_valid shape: torch.Size([29799, 80])\n",
            "y_valid shape: torch.Size([29799])\n",
            "***************************************\n",
            "X_test shape: torch.Size([48603, 80])\n",
            "X1_test shape: torch.Size([48603, 80])\n",
            "y_test shape: torch.Size([48603])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBjMZF1wGaUp"
      },
      "source": [
        "# for grader use only\n",
        "\n",
        "# insert grade here  (out of 4)\n",
        "\n",
        "# G[1] =\n",
        "#\n",
        "# please justify point subtractions when needed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color = 'blue'> Question 2. Write a functioning classifier in PyTorch </font>\n",
        "\n",
        "Write code that defines a classification model for the above dataset, and all other functions that are needed for its training. Apply your model on the two datsets $X,X_1$ and report the accuracy. The classifier should operate on the GPU.\n",
        "\n",
        "**Hint:** Re-use code we discussed for the Softmax Regression module."
      ],
      "metadata": {
        "id": "s7I1lmGM0skC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## your answer goes here\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# I got the Softmax Regression module in the Course Whiteboard, no update yet for the Question 2.\n",
        "## The model will be updated in the Question 3 according the data we are using and the question we have which is classifier.\n",
        "### I only updated the input/output size to get model run altgouth we have very low accoury.\n",
        "class SoftMaxRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear = nn.Linear(80, 40) ### I adjustd the input/outpus size based on the data\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        y = self.flatten(x)\n",
        "        y = self.linear(y)\n",
        "        return y\n",
        "\n"
      ],
      "metadata": {
        "id": "na0el-GE1qtY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "558b6998-c836-40a0-9c46-c410ab4b706b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### A function to train the model above.\n",
        "\n",
        "def train_model(model, train_loader, valid_loader, num_epochs=10, learning_rate=0.01):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += (predicted == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "        train_acc = correct / total\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in valid_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            outputs = model(x)\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += (predicted == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "    valid_acc = correct / total\n",
        "    print(f\"Validation Accuracy: {valid_acc:.4f}\")\n",
        "    return valid_acc"
      ],
      "metadata": {
        "id": "q6tDuo_uUoTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### getting the datasets\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "train_dataset_X = TensorDataset(X_train, y_train)\n",
        "valid_dataset_X = TensorDataset(X_valid, y_valid)\n",
        "test_dataset_X = TensorDataset(X_test, y_test)\n",
        "\n",
        "train_dataset_X1 = TensorDataset(X1_train, y_train)\n",
        "valid_dataset_X1 = TensorDataset(X1_valid, y_valid)\n",
        "test_dataset_X1 = TensorDataset(X1_test, y_test)\n",
        "\n",
        "train_loader_X = DataLoader(train_dataset_X, batch_size=batch_size, shuffle=True)\n",
        "valid_loader_X = DataLoader(valid_dataset_X, batch_size=batch_size, shuffle=False)\n",
        "test_loader_X = DataLoader(test_dataset_X, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "train_loader_X1 = DataLoader(train_dataset_X1, batch_size=batch_size, shuffle=True)\n",
        "valid_loader_X1 = DataLoader(valid_dataset_X1, batch_size=batch_size, shuffle=False)\n",
        "test_loader_X1 = DataLoader(test_dataset_X1, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "HTu--VMpVLO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### the model on the two datsets  X,X1  and report the accuracy\n",
        "\n",
        "print(\"\\nTraining model on X dataset:\")\n",
        "model= SoftMaxRegression()\n",
        "train_model(model, train_loader_X, valid_loader_X)\n",
        "\n",
        "print(\"\\nTraining model on X1 dataset:\")\n",
        "train_model(model, train_loader_X1, valid_loader_X1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkEoDW8tV-Cn",
        "outputId": "48ed489b-eeda-44de-a2d2-f244724fbede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model on X dataset:\n",
            "Epoch [1/10], Loss: 1288.8102, Train Acc: 0.1444\n",
            "Epoch [2/10], Loss: 1241.8357, Train Acc: 0.1791\n",
            "Epoch [3/10], Loss: 1206.2062, Train Acc: 0.1791\n",
            "Epoch [4/10], Loss: 1180.8257, Train Acc: 0.1791\n",
            "Epoch [5/10], Loss: 1163.4441, Train Acc: 0.1791\n",
            "Epoch [6/10], Loss: 1151.2023, Train Acc: 0.1791\n",
            "Epoch [7/10], Loss: 1142.2411, Train Acc: 0.1791\n",
            "Epoch [8/10], Loss: 1135.3668, Train Acc: 0.1791\n",
            "Epoch [9/10], Loss: 1130.3449, Train Acc: 0.1791\n",
            "Epoch [10/10], Loss: 1125.7530, Train Acc: 0.1791\n",
            "Validation Accuracy: 0.0763\n",
            "\n",
            "Training model on X1 dataset:\n",
            "Epoch [1/10], Loss: 1110.4701, Train Acc: 0.1791\n",
            "Epoch [2/10], Loss: 1094.1163, Train Acc: 0.1794\n",
            "Epoch [3/10], Loss: 1080.8656, Train Acc: 0.1820\n",
            "Epoch [4/10], Loss: 1069.4109, Train Acc: 0.1919\n",
            "Epoch [5/10], Loss: 1059.1643, Train Acc: 0.2049\n",
            "Epoch [6/10], Loss: 1049.8207, Train Acc: 0.2200\n",
            "Epoch [7/10], Loss: 1041.2485, Train Acc: 0.2312\n",
            "Epoch [8/10], Loss: 1033.7713, Train Acc: 0.2398\n",
            "Epoch [9/10], Loss: 1026.3092, Train Acc: 0.2459\n",
            "Epoch [10/10], Loss: 1019.3622, Train Acc: 0.2517\n",
            "Validation Accuracy: 0.2370\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2369878183831672"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## We got very low accuracy with the SoftMaxRegression model that comes from the Canvas.\n",
        "#Becasue a regression model is a basic linear classifier with a single layer neural network.\n",
        "# Without a activation function as Relu, the model only work well on linear boundaries.\n"
      ],
      "metadata": {
        "id": "t7zan6UnhFyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlICv7kW1qte"
      },
      "source": [
        "# for grader use only\n",
        "\n",
        "# insert grade here  (out of 8)\n",
        "\n",
        "# G[2] =\n",
        "#\n",
        "# please justify point subtractions when needed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color = 'blue'> Question 3. Maximize the accuracy on the two datasets </font>\n",
        "\n",
        "Augment your classifier from Question-2 with any number and type of layers you want, with the goal to maximize the **validation** accuracy you achieve on the two datasets. Feel free to use any stopping criterion you want for the training process. The networks for $X$ and $X_1$ do not have be of the same architecture.\n",
        "\n",
        "Show your code, and add a text cell summarizing your idea and findings. Finally apply your models to the **test** set, and report the accuracy. Feel free to discuss your validation accuracy on Canvas. Also please avoid looking at the test set, until the very end.\n",
        "\n",
        "**Rubric**: All complete answers get 8 points, and the **top** test accuracy reported gets an extra 10\\% in the final quiz."
      ],
      "metadata": {
        "id": "gDmA1ZZL152G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## your answer goes here\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(80, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(256, 40)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "model_X_updated = Classifier().to(device)\n"
      ],
      "metadata": {
        "id": "ySrVeueW31b_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, valid_loader, num_epochs=100, patience=5):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    best_val_acc = 0\n",
        "    early_stop_counter = 0\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss, correct, total = 0, 0, 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        train_acc = correct / total\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in valid_loader:\n",
        "                inputs, labels = inputs.cuda(), labels.cuda()\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = outputs.max(1)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "        val_acc = correct / total\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "        # Early Stopping\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            early_stop_counter = 0\n",
        "        else:\n",
        "            early_stop_counter += 1\n",
        "            if early_stop_counter >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "PGEmoGBWZTVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train models\n",
        "\n",
        "## acc_X = train_model(model_X, train_loader_X, valid_loader_X)\n",
        "print(\"Training model on X dataset:\")\n",
        "train_model(model_X_updated, train_loader_X, valid_loader_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUpCs15VZVYG",
        "outputId": "aa346a18-96d3-454d-aa07-8d1f70d32e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model on X dataset:\n",
            "Epoch [1/100], Train Acc: 0.4362, Val Acc: 0.1171\n",
            "Epoch [2/100], Train Acc: 0.4843, Val Acc: 0.1164\n",
            "Epoch [3/100], Train Acc: 0.4955, Val Acc: 0.1050\n",
            "Epoch [4/100], Train Acc: 0.5026, Val Acc: 0.1657\n",
            "Epoch [5/100], Train Acc: 0.5092, Val Acc: 0.1182\n",
            "Epoch [6/100], Train Acc: 0.5112, Val Acc: 0.2476\n",
            "Epoch [7/100], Train Acc: 0.5137, Val Acc: 0.2465\n",
            "Epoch [8/100], Train Acc: 0.5166, Val Acc: 0.2437\n",
            "Epoch [9/100], Train Acc: 0.5188, Val Acc: 0.0662\n",
            "Epoch [10/100], Train Acc: 0.5182, Val Acc: 0.0345\n",
            "Epoch [11/100], Train Acc: 0.5207, Val Acc: 0.0528\n",
            "Early stopping triggered.\n",
            "Best Validation Accuracy: 0.2476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model_X_updated, train_loader_X1, valid_loader_X1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIj499RmjzDb",
        "outputId": "c749de2f-3577-4ef8-e690-d8a931a6dbff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Train Acc: 0.4323, Val Acc: 0.5178\n",
            "Epoch [2/100], Train Acc: 0.4928, Val Acc: 0.5290\n",
            "Epoch [3/100], Train Acc: 0.5052, Val Acc: 0.5296\n",
            "Epoch [4/100], Train Acc: 0.5143, Val Acc: 0.5333\n",
            "Epoch [5/100], Train Acc: 0.5192, Val Acc: 0.5408\n",
            "Epoch [6/100], Train Acc: 0.5249, Val Acc: 0.5389\n",
            "Epoch [7/100], Train Acc: 0.5292, Val Acc: 0.5435\n",
            "Epoch [8/100], Train Acc: 0.5337, Val Acc: 0.5372\n",
            "Epoch [9/100], Train Acc: 0.5370, Val Acc: 0.5459\n",
            "Epoch [10/100], Train Acc: 0.5397, Val Acc: 0.5459\n",
            "Epoch [11/100], Train Acc: 0.5419, Val Acc: 0.5492\n",
            "Epoch [12/100], Train Acc: 0.5456, Val Acc: 0.5521\n",
            "Epoch [13/100], Train Acc: 0.5481, Val Acc: 0.5488\n",
            "Epoch [14/100], Train Acc: 0.5503, Val Acc: 0.5500\n",
            "Epoch [15/100], Train Acc: 0.5525, Val Acc: 0.5490\n",
            "Epoch [16/100], Train Acc: 0.5562, Val Acc: 0.5492\n",
            "Epoch [17/100], Train Acc: 0.5599, Val Acc: 0.5492\n",
            "Early stopping triggered.\n",
            "Best Validation Accuracy: 0.5521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I updated the Softmax Regression(in Question-2) to a neural network with non-linearity.\n",
        "# I added hidden layers with ReLU activation to capture more complex patterns.\n",
        "# I used batch normalization to stabilize learning.\n",
        "# I added dropout to reduce overfitting.\n",
        "# I used Adam optimizer instead of plain SGD for better convergence.\n",
        "# I implemented early stopping.\n",
        "\n",
        "# Regarding the accuract results:\n",
        "#The X dataset, it is low,\n",
        "#The model failed to learn meaningful features from X or the data is highly noisy.\n",
        "\n",
        "#The X1 dataset, tehre is an improvement, meaning X1 has more useful features or the model learns better from it."
      ],
      "metadata": {
        "id": "SxtUhYrNmlzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "\n",
        "\n",
        "    test_acc = correct / total\n",
        "    return test_acc\n",
        "\n",
        "test_dataset_X = TensorDataset(X_test, y_test)\n",
        "test_loader_X = DataLoader(test_dataset_X, batch_size=256, shuffle=False)\n",
        "\n",
        "test_dataset_X1 = TensorDataset(X1_test, y_test)\n",
        "test_loader_X1 = DataLoader(test_dataset_X1, batch_size=256, shuffle=False)\n",
        "\n",
        "test_acc_X = test_model(model_X_updated, test_loader_X)\n",
        "test_acc_X1 = test_model(model_X_updated, test_loader_X1)\n",
        "\n",
        "print(f\"Test Accuracy on X dataset: {test_acc_X:.4f}\")\n",
        "print(f\"Test Accuracy on X1 dataset: {test_acc_X1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WD9_CrT5awl0",
        "outputId": "2e9cd57e-b162-43e8-fd1e-13cea2951014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy on X dataset: 0.0214\n",
            "Test Accuracy on X1 dataset: 0.5257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcYS1afK31cS"
      },
      "source": [
        "# for grader use only\n",
        "\n",
        "# insert grade here  (out of 8)\n",
        "\n",
        "# G[3] =\n",
        "#\n",
        "# please justify point subtractions when needed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# total score\n",
        "max_score = 20\n",
        "$inal_score = sum(G)*(100/max_score)"
      ],
      "metadata": {
        "id": "EZHVWBIjIuoy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}